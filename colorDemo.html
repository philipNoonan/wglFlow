<html>
<head>
</head>

<style>
  body {
    display: flex;
    flex-direction: column;
    font-family: 'Roboto', 'Noto', sans-serif;
    line-height: 1.5;
    background-color: #fbfbfb;
    margin: 20px;
  }

  .select {
    margin: 16px 0px;
    display: flex;
    flex-direction: column;
    max-width: 400px;
  }

  select {
    background-color: transparent;
    width: 100%;
    padding: 4px 0;
    font-size: 16px;
    color: rgba(0,0,0, 0.26);
    border: none;
    border-bottom: 1px solid rgba(0,0,0, 0.12);
  }

  select:focus {
    outline: none;
  }

  .select > label {
    font-size: 10pt;
    color: gray;
  }

  #console {
    color: red;
    font-size: 150%;
  }

  canvas {
    border: 1px solid #cccccd;
    background-color: white;
  }

  #tabcontainer {
    margin: 16px 0px;
  }

  #tabcontainer input {
    height: 35px;
    visibility: hidden;
  }

  label[for=tab1], label[for=tab2] {
    color: gray;
    cursor: pointer;
    display: block;
    float: left;
    height, : 40px;
    line-height: 40px;
    margin-right: 5px;
    padding: 0 20px;
    text-align: center;
  }
  
  #tabcontainer input:hover + label {
    background: lightgray;
    color: gray;
  }

  #tabcontainer input:checked + label {
    background: #f0f0f0;
    color: dimgray;
    position: relative;
    z-index: 6;
  }

  #tabcontent1, #tabcontent2 {
    background: #f0f0f0;
    opacity: 0;
    position: absolute;
    z-index: -100;
  }

  #tabcontainer input#tab1:checked ~ #tabcontent #tabcontent1,
  #tabcontainer input#tab2:checked ~ #tabcontent #tabcontent2 {
      opacity: 1;
      z-index: 100;
  }

  input.visible {
    visibility: visible !important;
  }


  video-stream {
    color: dimgray;
  }

  #synctab {
    margin: 16px;
    padding:0px;
    color: dimgray;
  }

  label[for=synccanvas] {
    display:block;    
  }

  #show-background-video {
    position: absolute;
    bottom: 50px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-background-color {
    position: absolute;
    bottom: 30px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-video-toggle, #show-color-toggle {
    visibility: visible !important;
    height: 15px !important;
    vertical-align:middle;
  }
</style>

<template id="video-stream">
  <style>
    :host {
      display: flex;
      flex-flow: row wrap;
    }

    canvas {
      align-self: center;
    }

    div {
      margin: 16px;
    }

    label {
      display: block;
    }
  </style>
  <div>
    <label>WebGL2.0-Compute Powered Optical Flow: wglFlow:</label>
    <canvas id="canvasGL" width="1696" height="960"></canvas>
  </div>
</template>

<body onload="onLoad()">
  <h2>wglFlow</h2>
  <div id="console">
    <!-- Print error messages here. -->
  </div>
  <div class="select">
    <label for="selectVideoDevice">Capture device with depth stream</label>
    <select id="selectVideoDevice"></select>
  </div>

  <button onclick="clickPoseNet()">Load PoseNet</button>
  <button onclick="clickBodyPix()">Load BodyPix</button>


  <div id="tabcontainer">
    <input id="tab1" type="radio" name="tabs" value="basic" checked="checked" data-ontaboff="stopBasicTab" data-ontabon="startBasicTab"/>
    <div id="tabcontent">
      <div id = tabcontent1>
        <video-stream></video-stream>
      </div>
  </div>

  <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>



  <script src="node_modules/gl-matrix/gl-matrix-min.js"></script>
  <script src="node_modules/mathjs/dist/math.js"></script>
  <script src="node_modules/stats.js/build/stats.min.js"></script>



  <script src="src/createAndCompileShader.js"></script>
  <script src="src/createComputeProgram.js"></script>
  <script src="src/createRenderProgram.js"></script>

  <script src="src/frame.js"></script>
  <script src="src/generateTexture.js"></script>
  <script src="src/webcamera.js"></script>
  <script src="src/render.js"></script>
  <script src="src/renderSkeleton.js"></script>


  <script src="shaders/copyImage.js"></script>
  <script src="shaders/edgeDetect.js"></script>
  <script src="shaders/denseInverseSearch.js"></script>
  <script src="shaders/getFlowFromPart.js"></script>
  <script src="shaders/renderScreen.js"></script>
  <script src="shaders/getClickedPoint.js"></script>
  <script src="shaders/ploting.js"></script>
  <script src="shaders/skeleton.js"></script>
  <script src="shaders/checkIfNewImage.js"></script>

</body>









<script>
  let error = window.console.error;
  window.console.error = (message, ...rest) => {
    let target = document.querySelector('#console');
    error.call(window.console, message, ...rest);

    if (message instanceof Error) {
      message = `${message.name}: ${message.message}`;
    }

    target.innerHTML += `${message}<br>`;
  }

  var net;
  var poseNetLoaded = 0;
  var firstBodyPoseFound = 0;
  var bodyPoseFound = 0;
  var bodyPose;

  var segmentation;
  var bodyPixLoaded = 0;
  var bodyMapFound = 0;
  var firstbodyMapFound = 0;

  function clickPoseNet() {
    loadPoseNet();
  }

  function clickBodyPix() {
    loadBodyPix();
  }

  async function loadPoseNet() {
    net = await posenet.load({
    architecture: 'ResNet50',
    outputStride: 32,
    inputResolution: { width: 257, height: 200 },
    quantBytes: 2
    });
    poseNetLoaded = 1;  
  }

  async function getBodyPose(image, net) {
    var bPWorking = 0;
    if (bodyPoseFound == 0 && bPWorking == 0) {
      bPWorking = 1;
      bodyPoseFound = 0;
      const bP = await net.estimateSinglePose(image, {flipHorizontal: false});
      bodyPose = JSON.parse(JSON.stringify(bP));
      bodyPoseFound = 1;
      bpWorking = 0;
      if (firstBodyPoseFound == 0) {
        firstBodyPoseFound = 1;
      }
    }
  }

  async function loadBodyPix() {
    net = await bodyPix.load({
      architecture: 'MobileNetV1',
      outputStride: 16,
      multiplier: 0.75,
      quantBytes: 2
    });
    bodyPixLoaded = 1;

  }

  async function getBodyMap(image, net) {
    const seggy = await net.segmentPersonParts(image, {
      flipHorizontal: false,
      internalResolution: 'medium',
      segmentationThreshold: 0.7
    });
    segmentation = seggy;
    bodyMapFound = 1;
    if (firstbodyMapFound == 0)
    {
      firstbodyMapFound = 1;
    }
  }



  let tabs = document.getElementsByName("tabs");
  let videos = {depth: null, color: null};

  let selectedtab = tabs[0];
  for(let i = 0; i < tabs.length; i++) {
    tabs[i].onclick = function() {
      if(this !== selectedtab) {
        window[selectedtab.dataset.ontaboff](); 
        selectedtab = this;
        window[selectedtab.dataset.ontabon](); 
      }
    };
  }
  
  function stopVideo(video) {
    if (video && video.srcObject) {
      const cs = video.srcObject;
      for (let track of cs.getTracks()) {
        track.stop();
      }
      video.srcObject = null;
    }
  }

  function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  const videoToggle = document.getElementById("show-video-toggle");


  var frameCounter = 0;

  var stats = new Stats();
  stats.showPanel(0);
  stats.domElement.style.cssText = 'position:absolute;top:0px;right:0px;';
  document.body.appendChild(stats.dom);

  // vao
  var vaoRender;
  var vaoSkeleton;
  var vaoPlotting;

  var renderProgram;
  var renderPlottingProgram;
  var renderSkeletonProgram;
  var skelePoints = [];

  var newImage = 1;

  var plottingBufferProgram;

  var copyImageProgram;
  var checkIfNewImageProgram;
  var edgeDetectProgram;
  var disSearchProgram;
  var getFlowFromPartProgram;

  var disDensificationProgram;

  var imageSize = [1280, 720];
  var numberOflevels = 4;

  function normalize(val, max, min) { return (val - min) / (max - min); }
	function divup(a, b) { return (a % b != 0) ? (a / b + 1) : (a / b); }



  customElements.define('video-stream', class extends HTMLElement {
    constructor() {
      super();
      const template = document.querySelector('#video-stream');
      const clone = document.importNode(template.content, true);
      const shadowRoot = this.attachShadow({ mode: 'open' });
      this.shadowRoot.appendChild(clone);

      this._frameLoop = this._frameLoop.bind(this);

      this.readBuffer = null;
      this.readFormat = null;
    }


    connectedCallback() {
      this.gl = this._configureGLContext();

      this.frameAvailableColor = false;

      this.videoColor = this._createOffscreenVideo();
      this.videoColor.oncanplay = _ => { this.frameAvailableColor = true; }
      this.videoColor.addEventListener("play", this._frameLoop);

      let hasTouchListeners = false;
      const onVideoTouchStart = _ => {
        hasTouchListeners = false;
        window.removeEventListener("touchstart", onVideoTouchStart, true);
        this.videoColor.play();
      }

      if (this.videoColor && this.videoColor.paused && !hasTouchListeners) {
        hasTouchListeners = true;
        window.addEventListener("touchstart", onVideoTouchStart, true);
      }
    }

    _createOffscreenVideo() {
      return Object.assign(document.createElement("video"), {
        autoplay: true,
        loop: true,
        crossOrigin: "anonymous",
        width: imageSize[0],
        height: imageSize[1]
      });
    }
    
    _frameLoopColor() {

    }

    async _frameLoop() {
      const gl = this.gl;
      stats.begin();

      gl.clearColor(0, 0, 0, 0);
      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

      if (poseNetLoaded == 1) {
        getBodyPose(this.videoColor, net);
      }

      if (bodyPixLoaded == 1) {
        getBodyMap(this.videoColor, net)
      }

      let c = this.shadowRoot.getElementById("canvasGL");




    

      if (this.frameAvailableColor) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.color_texture);
        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RGBA, gl.UNSIGNED_BYTE, this.videoColor);
        gl.generateMipmap(gl.TEXTURE_2D);


      }

      if (frameCounter > 0) {
        checkIfNewImage(gl, gl.lastColor_texture, gl.color_texture);
      }
      
      if (frameCounter > 0 && this.frameAvailableColor && gl.newImage == 1) {
        for (let lvl = 0; lvl < numberOflevels; lvl++) {
        calcGradient(gl, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl);
        }

        for (let lvl = numberOflevels - 1; lvl >= 0; lvl--) {
          inverseSearch(gl, lvl, imageSize[0], imageSize[1]);
          densify(gl, lvl, imageSize[0], imageSize[1]);
        }
        //gl.newImage = 0;

      }


      if (bodyMapFound == 1) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.mask_texture);
        //var seg = Float32Array.from(segmentation.data);

        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RED_INTEGER, gl.INT, segmentation.data);

        var sumFlow = getFlowFromPart(gl, gl.mask_texture);

        uploadGraphPoints(gl, sumFlow[1]);

        //console.log(sumFlow[0], sumFlow[1]);




      }

      render(gl, c.width, c.height);


      if (firstbodyMapFound == 1)
      { 
        for (let person = 0; person < segmentation.allPoses.length; person++)
        {
          if (segmentation.allPoses[person].score < 0.3) {
            continue;
          }
            if (bodyMapFound == 1)
            {
          ////const adjacentKeyPoints =
          ////posenet.getAdjacentKeyPoints(bodyPose.keypoints, 0.001);
          // // adjacentKeyPoints.forEach((keypoints) => {
          // //   skelePoints.push(keypoints[0].position.x);
          // //   skelePoints.push(keypoints[0].position.y);
          // //   //skelePoints.push(keypoints[1].position[0]);
          // //   //skelePoints.push(keypoints[1].position[1]);
          // // });
          //console.log(bodyPose);

            skelePoints = [];
            for (let iter = 0; iter < segmentation.allPoses[person].keypoints.length; iter++)
            {
              if (segmentation.allPoses[person].keypoints[iter].score < 0.1) {
                continue;
              }
              skelePoints.push(segmentation.allPoses[person].keypoints[iter].position.x);
              skelePoints.push(segmentation.allPoses[person].keypoints[iter].position.y);
            }
            bodyPoseFound = 0;
          }
          gl.useProgram(renderSkeletonProgram);
          gl.bindVertexArray(gl.vaoSkeleton);
          gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
          gl.viewport(c.width / 2.0, 240, c.width / 2.0, c.height - 240);
          gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);
          let sp = Float32Array.from(skelePoints);
          gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);
          gl.drawArrays(gl.POINTS, 0, skelePoints.length);     
          gl.bindVertexArray(null);

          }
 
      }

      if (firstBodyPoseFound == 1)
      {
        if (bodyPoseFound == 1)
        {
          const adjacentKeyPoints =
          posenet.getAdjacentKeyPoints(bodyPose.keypoints, 0.001);
          // // adjacentKeyPoints.forEach((keypoints) => {
          // //   skelePoints.push(keypoints[0].position.x);
          // //   skelePoints.push(keypoints[0].position.y);
          // //   //skelePoints.push(keypoints[1].position[0]);
          // //   //skelePoints.push(keypoints[1].position[1]);
          // // });
          //console.log(bodyPose);
          skelePoints = [];
          for (let iter = 0; iter < bodyPose.keypoints.length; iter++)
          {
            skelePoints.push(bodyPose.keypoints[iter].position.x);
            skelePoints.push(bodyPose.keypoints[iter].position.y);
          }
          bodyPoseFound = 0;
        }
        gl.useProgram(renderSkeletonProgram);
        gl.bindVertexArray(gl.vaoSkeleton);
        gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
        gl.viewport(c.width / 2.0, 240, c.width / 2.0, c.height - 240);
        gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);
        let sp = Float32Array.from(skelePoints);
        gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);
        gl.drawArrays(gl.POINTS, 0, skelePoints.length);     
        gl.bindVertexArray(null);
      }



      if (this.frameAvailableColor && gl.newImage == 1) {
        //for (let lvl = 0; lvl < numberOflevels; lvl++) {
       // copyImage(gl, gl.lastColor_texture, gl.color_texture, lvl, imageSize[0], imageSize[1], gl.RGBA8UI);
      //  copyImage(gl, gl.lastGradient_texture, gl.gradient_texture, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl, gl.RGBA32F);
      //  copyImage(gl, gl.lastGrey_texture, gl.grey_texture, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl, gl.R32F);
        //}
          let tempVal = gl.lastColor_texture;
          gl.lastColor_texture = gl.color_texture;
          gl.color_texture = tempVal;
          
          let tempVal0 = gl.lastGradient_texture;
          gl.lastGradient_texture = gl.gradient_texture;
          gl.gradient_texture = tempVal0;

          gl.newImage = 0;

      }



      frameCounter++;
      stats.end();

        //await sleep(30);


      if (!this.paused)
        window.requestAnimationFrame(this._frameLoop);

    }






    // Creates WebGL/WebGL2 context used to upload depth video to texture,
    // read the pixels to Float buffer and optionElally render the texture.
    _configureGLContext() {
      const canvas = this.shadowRoot.getElementById("canvasGL");
      const gl = canvas.getContext('webgl2-compute', {antialias: false});
      if (gl) {
        // The extension tells us if we can use single component R32F texture format.
        gl.color_buffer_float_ext = gl.getExtension('EXT_color_buffer_float');
      } else {
        gl = canvas.getContext("webgl");
        gl.getExtension("OES_texture_float");
      }



      // VERTEX FRAGMENT SHADERS
      renderProgram = createRenderProgram(gl, vertexShaderSource, fragmentShaderSource);
      renderPlottingProgram = createRenderProgram(gl, plottingVertexShaderSource, plottingFragmentShaderSource);
      renderSkeletonProgram = createRenderProgram(gl, skeletonVertexShaderSource, skeletonFragmentShaderSource);

      copyImageProgram = createComputeProgram(gl, copyImageSource);
      checkIfNewImageProgram = createComputeProgram(gl, checkIfNewImageSource);
      
      plottingBufferProgram = createComputeProgram(gl, plottingBufferSource);  


      edgeDetectProgram = createComputeProgram(gl, edgeDetectSource);
      disSearchProgram = createComputeProgram(gl, disSearchSource);
      disDensificationProgram = createRenderProgram(gl, disDensificationVertexShaderSource, disDensificationFragmentShaderSource);
      getFlowFromPartProgram = createComputeProgram(gl, getFlowFromPartSource);
      
      gl.enable(gl.BLEND);
      gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);




      gl.useProgram(renderProgram);
      vaoRender = gl.createVertexArray();
      gl.bindVertexArray(vaoRender);

      var vertex_location = gl.getAttribLocation(renderProgram, "v");
      gl.enableVertexAttribArray(vertex_location);

      var vertex_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, vertex_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0,0,1,0,1,1,0,1]), gl.STATIC_DRAW);

      var index_buffer= gl.createBuffer();
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, index_buffer);
      gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([0,1,2,0,2,3]), gl.STATIC_DRAW);

      gl.bindBuffer(gl.ARRAY_BUFFER, gl.vertex_buffer);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);


      gl.useProgram(renderSkeletonProgram);
      vaoSkeleton = gl.createVertexArray();
      gl.bindVertexArray(vaoSkeleton);

      let arrSkele = new Float32Array(17 * 2);
      var skeleton_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, skeleton_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, arrSkele, gl.DYNAMIC_COPY);

      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      var mask_texture = generateTexture(gl, gl.TEXTURE_2D, gl.R32I, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST_MIPMAP_NEAREST);

      var color_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);
      var lastColor_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var gradient_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR);
      var lastGradient_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR);

      var densify_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR);

      var flow_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var sparseFlow_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0] / 4.0, imageSize[1] / 4.0, 1, gl.LINEAR, gl.LINEAR);

      var render_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var test_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);


      



      //Texture

      var frameBuffers = [];

      for (let lvl = 0; lvl < numberOflevels; lvl++) {
        var fb = gl.createFramebuffer();
        gl.bindFramebuffer(gl.FRAMEBUFFER, fb);

        let depthTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, depthTexture);

        gl.texImage2D(gl.TEXTURE_2D, 0, gl.DEPTH_COMPONENT24,
                        imageSize[0] >> lvl, imageSize[1] >> lvl, 0,
                        gl.DEPTH_COMPONENT, gl.UNSIGNED_INT, null);

        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.TEXTURE_2D, depthTexture, 0);
        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, densify_texture, lvl);
        //gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT1, gl.TEXTURE_2D, topFlow_texture, lvl);

        gl.bindFramebuffer(gl.FRAMEBUFFER, null);

        frameBuffers.push(fb);

      }

      let checkData = new Uint32Array(1);
      var ssboCheckData = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboCheckData);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, checkData, gl.DYNAMIC_COPY);

      let chestFlowData = new Float32Array(16 * 2);
      var ssboChestFlowData = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboChestFlowData);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, chestFlowData, gl.DYNAMIC_COPY);


      gl.useProgram(renderPlottingProgram);
      vaoPlotting = gl.createVertexArray();
      gl.bindVertexArray(vaoPlotting);

      let emptyGraphPoints = new Float32Array(2*1024);
      var ssboGraphX = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphX);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);


      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphX);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);


      gl.newImage = newImage;


      gl.vertex_buffer = vertex_buffer;
      gl.vertex_location = vertex_location;
      gl.index_buffer = index_buffer;



      gl.vaoRender = vaoRender;
      gl.vaoSkeleton = vaoSkeleton;
      gl.vaoPlotting = vaoPlotting;

      gl.color_texture = color_texture;
      gl.lastColor_texture = lastColor_texture;

      gl.gradient_texture = gradient_texture;
      gl.lastGradient_texture = lastGradient_texture;

      gl.densify_texture = densify_texture;
      gl.flow_texture = flow_texture;

      gl.sparseFlow_texture = sparseFlow_texture;

      gl.render_texture = render_texture;

      gl.test_texture = test_texture;

      gl.frameBuffers = frameBuffers;

      gl.skeleton_buffer = skeleton_buffer;

      gl.ssboCheckData = ssboCheckData;
      gl.ssboChestFlowData = ssboChestFlowData;
      gl.ssboGraphX = ssboGraphX;

      gl.mask_texture = mask_texture;

      return gl;
    }

    async loadStream(deviceId) {
      stopVideo(videos.color);
    

      const getUserMediaColor = () => {
        // add ?allow=all to URL to allow listing all devices (incl. those not supporting depth).
        if (!deviceId && (new URL(window.location)).searchParams.get("allow") !== "all") {
          return webCamera.getColorStream();
        }

        const constraints = {
          video: {
            deviceId: deviceId ? { exact: deviceId } : {}
          }
        }

        return navigator.mediaDevices.getUserMediaColor(constraints);
      }

      try {
        const streamColor = await getUserMediaColor();
        this.videoColor.srcObject = streamColor;
        videos.color = this.videoColor;

        //videos.color = this.videoDepth;

        const tracksColor = streamColor.getVideoTracks()[0];
        if (tracksColor.getSettings) {
          this.colorDeviceId = tracksColor.getSettings().deviceId;
        }

      } catch (err) {
        console.error(err);
      }
    }
  });

  function populateSelectElement(devices) {
    const selectEl = document.querySelector('#selectVideoDevice');
    const videoStreamEl = document.querySelector('video-stream');

    let selected = selectEl.value;

    while (selectEl.firstChild) {
      selectEl.removeChild(selectEl.firstChild);
    }

    let selectedDeviceStillExists = false;
    for (let i = 0; i < devices.length; ++i) {
      const info = devices[i];
      if (info.kind !== 'videoinput') {
        continue;
      }

      const optionEl = document.createElement('option');
      optionEl.value = info.deviceId;
      optionEl.text = info.label || 'camera ' + (selectEl.length + 1);
      selectEl.appendChild(optionEl);

      if (optionEl.value === selected) {
        selectedDeviceStillExists = true;
      }
    }

    if (selectedDeviceStillExists) {
      selectEl.value = selected;
    } else if (!selected) {
      // If no other device is selected, set the initial selection to depth device.
      if (videoStreamEl.colorDeviceId) {
        selectEl.value = videoStreamEl.colorDeviceId;
      }
    }


  }

  function onLoad() {
    const videoStreamEl = document.querySelector('video-stream');
    const selectEl = document.querySelector('#selectVideoDevice');

    selectEl.onchange = async event => {
      selectEl.disabled = true;
      const deviceId = event.target.value;

      await videoStreamEl.loadStream(deviceId);

      const devices = await navigator.mediaDevices.enumerateDevices();
      populateSelectElement(devices);
      if (selectedtab.value != "basic") {
        // It is on by default; stop rendering it if not visible.
        stopBasicTab();
      }

      selectEl.disabled = false;
    };
    selectEl.dispatchEvent(new Event('change', { 'bubbles': true }))
  }
</script>
</html>
