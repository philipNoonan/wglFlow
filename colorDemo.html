<html>
<head>
</head>

<style>
  body {
    display: flex;
    flex-direction: column;
    font-family: 'Roboto', 'Noto', sans-serif;
    line-height: 1.5;
    background-color: #fbfbfb;
    margin: 20px;
  }

  .select {
    margin: 16px 0px;
    display: flex;
    flex-direction: column;
    max-width: 400px;
  }

  /* select {
    background-color: transparent;
    width: 100%;
    padding: 4px 0;
    font-size: 16px;
    color: rgba(0,0,0, 0.26);
    border: none;
    border-bottom: 1px solid rgba(0,0,0, 0.12);
  } */

  select:focus {
    outline: none;
  }

  .select > label {
    font-size: 10pt;
    color: gray;
  }

  #console {
    color: red;
    font-size: 150%;
  }

  canvas {
    border: 1px solid #cccccd;
    background-color: white;
  }

  #tabcontainer {
    margin: 16px 0px;
  }

  #tabcontainer input {
    height: 35px;
    visibility: hidden;
  }

  label[for=tab1], label[for=tab2] {
    color: gray;
    cursor: pointer;
    display: block;
    float: left;
    height, : 40px;
    line-height: 40px;
    margin-right: 5px;
    padding: 0 20px;
    text-align: center;
  }
  
  #tabcontainer input:hover + label {
    background: lightgray;
    color: gray;
  }

  #tabcontainer input:checked + label {
    background: #f0f0f0;
    color: dimgray;
    position: relative;
    z-index: 6;
  }

  #tabcontent1, #tabcontent2 {
    background: #f0f0f0;
    opacity: 0;
    position: absolute;
    z-index: -100;
  }

  #tabcontainer input#tab1:checked ~ #tabcontent #tabcontent1,
  #tabcontainer input#tab2:checked ~ #tabcontent #tabcontent2 {
      opacity: 1;
      z-index: 100;
  }

  input.visible {
    visibility: visible !important;
  }


  video-stream {
    color: dimgray;
  }

  #synctab {
    margin: 16px;
    padding:0px;
    color: dimgray;
  }

  label[for=synccanvas] {
    display:block;    
  }

  #show-background-video {
    position: absolute;
    bottom: 50px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-background-color {
    position: absolute;
    bottom: 30px;
    right: 25px;
    color: gray;
    z-index: 5;
    height: 20px;
    text-align: right;
  }
  #show-video-toggle, #show-color-toggle {
    visibility: visible !important;
    height: 15px !important;
    vertical-align:middle;
  }
</style>

<template id="video-stream">
  <style>
    :host {
      display: flex;
      flex-flow: row wrap;
    }

    canvas {
      align-self: center;
    }

    div {
      margin: 16px;
    }

    label {
      display: block;
    }
  </style>

</template>

<body onload="onLoad()">

  <div id="no-support" style="display: none">
    <p><mark class="secondary" style="margin-right: 0.5em"></mark> It seems like WebGL 2.0 Compute is not available on your browser. Make sure you are on a system with WebGL 2.0 Compute enabled.</p>
    <p>Have you tried to open your browser using these arguments ?</p>
    <p>Windows: </p>
    <pre>chrome.exe --use-cmd-decoder=passthrough --use-angle=gl --enable-webgl2-compute-context</pre>
    <p>Linux - USE CHROME DEV: </p>
    <pre>google-chrome-unstable --use-gl=angle --use-angle=gl --use-cmd-decoder=passthrough --enable-webgl2-compute-context</pre>
  </div>

  <h2>wglFlow</h2>
  <div id="console">
    <!-- Print error messages here. -->
  </div>
  <div class="select">
    <label for="selectVideoDevice">Capture device with depth stream</label>
    <select id="selectVideoDevice"></select>
  </div>

  <!-- <button onclick="clickPoseNet()">Load PoseNet</button> -->
  <!-- <button onclick="clickBodyPix()">Load BodyPix</button> -->

  <input id="myInput" type="file" accept="video/*" style="visibility:hidden" />


  <!-- <div id="tabcontainer"> -->
    <!-- <input id="tab1" type="radio" name="tabs" value="basic" checked="checked" data-ontaboff="stopBasicTab" data-ontabon="startBasicTab"/> -->
    <!-- <div id="tabcontent"> -->
      <!-- <div id = tabcontent1>
        <video-stream></video-stream>
      </div> -->
    <!-- </div> -->

  <div>
    <!-- <label>WebGL2.0-Compute Powered Optical Flow: wglFlow:</label> -->
    <canvas id="canvasGL" width="1600" height="900"></canvas>
  </div>

  <!-- <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.2"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix@2.0"></script>

  <script type="text/javascript" src="node_modules/dat.gui/build/dat.gui.min.js"></script>



  <script src="node_modules/gl-matrix/gl-matrix-min.js"></script>
  <script src="node_modules/mathjs/dist/math.js"></script>
  <script src="node_modules/stats.js/build/stats.min.js"></script>



  <script src="src/createAndCompileShader.js"></script>
  <script src="src/createComputeProgram.js"></script>
  <script src="src/createRenderProgram.js"></script>

  <script src="src/frame.js"></script>
  <script src="src/generateTexture.js"></script>
  <script src="src/webcamera.js"></script>
  <script src="src/render.js"></script>
  <script src="src/renderSkeleton.js"></script>


  <script src="shaders/copyImage.js"></script>
  <script src="shaders/edgeDetect.js"></script>
  <script src="shaders/denseInverseSearch.js"></script>
  <script src="shaders/getFlowFromPart.js"></script>
  <script src="shaders/renderScreen.js"></script>
  <script src="shaders/getClickedPoint.js"></script>
  <script src="shaders/ploting.js"></script>
  <script src="shaders/skeleton.js"></script>
  <script src="shaders/checkIfNewImage.js"></script>
  <script src="shaders/fft.js"></script>

</body>









<script>
  let error = window.console.error;
  window.console.error = (message, ...rest) => {
    let target = document.querySelector('#console');
    error.call(window.console, message, ...rest);

    if (message instanceof Error) {
      message = `${message.name}: ${message.message}`;
    }

    target.innerHTML += `${message}<br>`;
  }

  var net;
  var poseNetLoaded = 0;
  var firstBodyPoseFound = 0;
  var bodyPoseFound = 0;
  var bodyPose;

  var segmentation;
  var bodyPixLoaded = 0;
  var bodyMapFound = 0;
  var firstbodyMapFound = 0;

  function getCursorPosition(canvas, event) {
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    const y = event.clientY - rect.top;
    mouseClickPos[0] = (x / (canvas.width / 2));
    mouseClickPos[1] = y / (canvas.height - 240.0);
    //console.log("x: " + mouseClickPos[0] + " y: " + mouseClickPos[1]);


  }

  function clickPoseNet() {
    loadPoseNet();
  }

  function clickBodyPix() {
    loadBodyPix();
  }

  async function loadPoseNet() {
    net = await posenet.load({
    architecture: 'ResNet50',
    outputStride: 32,
    inputResolution: { width: 257, height: 200 },
    quantBytes: 2
    });
    poseNetLoaded = 1;  
  }

  async function getBodyPose(image, net) {
    var bPWorking = 0;
    if (bodyPoseFound == 0 && bPWorking == 0) {
      bPWorking = 1;
      bodyPoseFound = 0;
      const bP = await net.estimateSinglePose(image, {flipHorizontal: false});
      bodyPose = JSON.parse(JSON.stringify(bP));
      bodyPoseFound = 1;
      bpWorking = 0;
      if (firstBodyPoseFound == 0) {
        firstBodyPoseFound = 1;
      }
    }
  }

  async function loadBodyPix() {
    net = await bodyPix.load({
      architecture: 'ResNet50',
      outputStride: 16,
      multiplier: 1.0,
      quantBytes: 2
    });
    bodyPixLoaded = 1;

  }

  async function getBodyMap(image, net, mppmFlag) {
    if (mppmFlag == true) {
      const seggy = await net.segmentMultiPersonParts(image, {
      flipHorizontal: false,
      internalResolution: 'medium',
      segmentationThreshold: 0.5,
      maxDetections: 10,
      scoreThreshold: 0.2,
      nmsRadius: 20,
      minKeypointScore: 0.3,
      refineSteps: 20
    });
    segmentation = seggy;

    }
    else {
      const seggy = await net.segmentPersonParts(image, {
        flipHorizontal: false,
        internalResolution: 'medium',
        segmentationThreshold: 0.7
      });
      segmentation = seggy;

    }

    bodyMapFound = 1;
    if (firstbodyMapFound == 0)
    {
      firstbodyMapFound = 1;
    }
  }



  let tabs = document.getElementsByName("tabs");
  let videos = {depth: null, color: null};
  var videoFF;
  var videoLoaded = 0;

  let selectedtab = tabs[0];
  for(let i = 0; i < tabs.length; i++) {
    tabs[i].onclick = function() {
      if(this !== selectedtab) {
        window[selectedtab.dataset.ontaboff](); 
        selectedtab = this;
        window[selectedtab.dataset.ontabon](); 
      }
    };
  }
  
  function stopVideo(video) {
    if (video && video.srcObject) {
      const cs = video.srcObject;
      for (let track of cs.getTracks()) {
        track.stop();
      }
      video.srcObject = null;
    }
  }

  function sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  const videoToggle = document.getElementById("show-video-toggle");


  var frameCounter = 0;
  var runningSum = 0;
  var runningMin = -5000;
  var runningMax = 5000;
  var plottingPoints = [];

  var savingRespirationData = false;

  var stats = new Stats();
  stats.showPanel(0);
  stats.domElement.style.cssText = 'position:absolute;top:0px;left:0px;';
  document.body.appendChild(stats.dom);


  var paramGUI = function() {
    this.speed = 10;
    this.renderLevel = 0;
    this.checkForNewFrames = true;
    this.checkMPPM = true;
    this.useWebcam = function() {
      connectedCallback();
      loadWebcam()
    };
    this.loadBP = function() {loadBodyPix()};
    this.loadFile = function() { 
      document.querySelector('input').addEventListener('change', extractFrames, false);
      document.getElementById('myInput').click();
    };
    this.saveToDisk = function() {
      savingRespirationData = true;
    };
    this.resolution = '640x480';
    this.manVai = 'manual';
    this.radius = 50;
    this.bmax = 20;
    this.bmin = 0;
  };

  var spd = 10;
  var rndrLevel = 0;
  var radius = 50;
  var bmin = 0;
  var bmax = 20;
  var checkFramesFlag = true;
  var checkMPPMFlag = true;

  var renderColor = true;
  var renderGrad = false;
  var renderFlow = true;

  var usingManual = true;
  var usingBodyPose = false;

  var gui = new dat.GUI();
  var param = new paramGUI();

  var folderWebcam = gui.addFolder('Webcam');
  folderWebcam.add(param, 'useWebcam').name('Use Webcam');
  var checkReso = folderWebcam.add(param, 'resolution', ['1920x1080', '1280x720', '640x480']);
  folderWebcam.open();
  
  var folderVideoFile = gui.addFolder('Video');
  folderVideoFile.add(param, 'loadFile').name('Load video file');
  folderVideoFile.open();

  var checkFrames = gui.add(param, 'checkForNewFrames');
  var checkMutliPersonPartMap = gui.add(param, 'checkMPPM');

  var spdcont = gui.add(param, 'speed', 1, 20);
  var rndrcont = gui.add(param, 'renderLevel', 0, 6);
  gui.add(param, 'loadBP').name('Load BodyPix');
  gui.add(param, 'saveToDisk').name('Save Respiration Data');
  var checkDetectMethod = gui.add(param, 'manVai', ['manual', 'bodyPose']);
  var radcont = gui.add(param, 'radius', 10, 255);
  var bmincont = gui.add(param, 'bmin', 0, 100);
  var bmaxcont = gui.add(param, 'bmax', 0, 100);

  spdcont.onChange(function(value) {
    spd = value;
  });

  rndrcont.onChange(function(value) {
    gl.rndrLevel = Math.ceil(value);
  });

  radcont.onChange(function(value) {
    radius = value;
  });

  checkFrames.onChange(function(value) {
    checkFramesFlag = value;
  });

  bmincont.onChange(function(value) {
    bmin = value;
  });

  bmaxcont.onChange(function(value) {
    bmax = value;
  });

  checkMutliPersonPartMap.onChange(function(value) {
    checkMPPMFlag = value;

  });

  checkReso.onChange(function(value) {
    frameAvailableColor = false;
    switch(value) {
      case '1920x1080':
        imageSize = [1920, 1080];
        setTextures(gl);
        loadWebcam();
        break;
      case '1280x720':
        imageSize = [1280, 720];
        setTextures(gl);
        loadWebcam();
        break;
      case '640x480':
        imageSize = [640, 480];
        setTextures(gl);
        loadWebcam();
        break;
      default:
        break;
      };
  });

  checkDetectMethod.onChange(function(value) {
    if (value == 'manual') {
      usingManual = true;
      usingBodyPose = false;

    }
    else if (value == 'bodyPose') {
      usingBodyPose = true;
      usingManual = false;

    }
  });

  // vao
  var vaoRender;
  var vaoSkeleton;
  var vaoPlotting;
  var vaoDensify;

  //var xhr = new XMLHttpRequest;

  var renderProgram;
  var renderPlottingProgram;
  var renderSkeletonProgram;
  var skelePoints = [];
  var skeleLines = [];

  var newImage = 1;
  var frameAvailableColor = false;

  var plottingBufferProgram;

  var dft1DProgram;
  var dft2DProgram;
  var fft1DProgram;
  var fft2DProgram;


  var copyImageProgram;
  var genMipMapProgram;
  var checkIfNewImageProgram;
  var edgeDetectProgram;
  var disSearchProgram;
  var getFlowFromPartProgram;
  var getFlowFromPointProgram;
  var makeMaskFromPointsProgram;

  var disDensificationProgram;

  var imageSize = [640, 480];
  var numberOflevels = 6;

  var gl;

  var mouseClickPos = [0.5, 0.5];






  function normalize(val, max, min) { return (val - min) / (max - min); }
	function divup(a, b) { return (a % b != 0) ? (a / b + 1) : (a / b); }


  function extractFrames() {
    videoFF = document.createElement('video');

    function initCanvas(e) {
      //console.log(this.videoWidth)
      //videoLoaded = 1;
      videoFF.width = videoFF.videoWidth;
      videoFF.height = videoFF.videoHeight;
      imageSize = [videoFF.width, videoFF.height];
      setTextures(gl);

    }

    function drawFrame(e) {
      // this.pause();

      // if (this.currentTime < this.duration) {
      // this.play();
      //console.log(this.currentTime);
      //}
    }

    function loadedData(e) {
      videoLoaded = 1;
    }

    videoFF.addEventListener('loadedmetadata', initCanvas, false);
    videoFF.addEventListener('loadeddata', loadedData, false);
    videoFF.addEventListener('timeupdate', drawFrame, false);
    videoFF.addEventListener("play", _frameLoop);


    videoFF.src = URL.createObjectURL(this.files[0]);
    videoFF.muted = true;
    videoFF.preload = 'auto';
    videoFF.loop = true;
    videoFF.crossOrigin = 'anonymous';
    videoFF.play();
  }

  // customElements.define('video-stream', class extends HTMLElement {
  //   constructor() {
  //     super();
  //     const template = document.querySelector('#video-stream');
  //     const clone = document.importNode(template.content, true);
  //     const shadowRoot = this.attachShadow({ mode: 'open' });
  //     this.shadowRoot.appendChild(clone);

  //     this._frameLoop = this._frameLoop.bind(this);

  //     this.readBuffer = null;
  //     this.readFormat = null;
  //   }





    function connectedCallback() {

      frameAvailableColor = false;

      this.videoColor = this._createOffscreenVideo();
      this.videoColor.oncanplay = _ => { frameAvailableColor = true; }
      this.videoColor.addEventListener("play", this._frameLoop);

      let hasTouchListeners = false;
      const onVideoTouchStart = _ => {
        hasTouchListeners = false;
        window.removeEventListener("touchstart", onVideoTouchStart, true);
        this.videoColor.play();
      }

      if (this.videoColor && this.videoColor.paused && !hasTouchListeners) {
        hasTouchListeners = true;
        window.addEventListener("touchstart", onVideoTouchStart, true);
      }
    }

    function _createOffscreenVideo() {
      return Object.assign(document.createElement("video"), {
        autoplay: true,
        loop: true,
        crossOrigin: "anonymous",
        width: imageSize[0],
        height: imageSize[1]
      });
    }
    
    // _frameLoopColor() {

    // }

    async function _frameLoop() {
      stats.begin();

      gl.clearColor(0, 0, 0, 0);
      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);

      if (poseNetLoaded == 1) {
        getBodyPose(this.videoColor, net);
      }

      if (videoLoaded == 0)
      {
        if (bodyPixLoaded == 1 && (frameCounter % Math.round(spd)) == 0 || Math.round(spd) <= 1) {
          getBodyMap(this.videoColor, net, checkMPPMFlag)
        }
      }
      else {
        if (bodyPixLoaded == 1 && (frameCounter % Math.round(spd)) == 0) {
          getBodyMap(videoFF, net, checkMPPMFlag)
        }
      }


      let c = document.getElementById("canvasGL");




    

      if (frameAvailableColor) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.color_texture);
        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RGBA, gl.UNSIGNED_BYTE, this.videoColor);
        gl.generateMipmap(gl.TEXTURE_2D);


      }

      
      if (videoLoaded == 1) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.color_texture);
        gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RGBA, gl.UNSIGNED_BYTE, videoFF);
        gl.generateMipmap(gl.TEXTURE_2D);
      }

      if (checkFramesFlag == true && frameCounter > 0) {
        checkIfNewImage(gl, gl.lastColor_texture, gl.color_texture);
      }
      
      if (frameCounter > 0 && (frameAvailableColor || videoLoaded) && (gl.newImage == 1 || checkFramesFlag == false)) {
 
        for (let lvl = 0; lvl < numberOflevels; lvl++) {
        calcGradient(gl, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl);
        }

        for (let lvl = numberOflevels - 1; lvl >= 0; lvl--) {
          inverseSearch(gl, lvl, imageSize[0], imageSize[1]);
          densify(gl, lvl, imageSize[0], imageSize[1]);
        }

        copyImage(gl, gl.flow_texture, gl.densify_texture, 0, imageSize[0], imageSize[1], gl.RGBA32F);
        //genMipMap(gl, gl.flow_texture, numberOflevels, imageSize[0], imageSize[1], gl.RGBA16F);

        //gl.newImage = 0;

        // doDFT2D(gl, -1);
        // doDFT2D(gl, 1);

        doFFT2D(gl, 1);

        //doFFT2D(gl, -1);

      }

      if (usingManual == true) {

        makeMaskFromPoints(gl, imageSize[0], imageSize[1], gl.mask_texture, mouseClickPos, radius);

        var sumFlow = getFlowFromPart(gl, gl.mask_texture);

        runningSum += sumFlow[1];

        plottingPoints[frameCounter % 1024] = runningSum;
        runningMax = Math.max(...plottingPoints);
        runningMin = Math.min(...plottingPoints);

        let scaledX = normalize(runningSum, runningMax, runningMin);

        uploadGraphPoints(gl, runningSum);
        //doDFTonPoints(gl);
        doFFTonPoints(gl, 1);
        //doFFTonPoints(gl, -1);

      }


      if (bodyMapFound == 1) {
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, gl.mask_texture);
        //var seg = Float32Array.from(segmentation.data);
        if (checkMPPMFlag == true) {
          try {
            for (let person = 0; person < segmentation.length; person++) {
              if (segmentation[person].pose.score > 0.3) {
                gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RED, gl.FLOAT, segmentation[person].data);
              }
            }
          }
          catch(error) {
            console.log(error);
          }

        }
        else {
          try {
            let seg = Float32Array.from(segmentation.data);
            gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, imageSize[0], imageSize[1], gl.RED, gl.FLOAT, seg); 
          }
          catch(error) {
            console.log(error);
          }

        }

        
        var sumFlow = getFlowFromPart(gl, gl.mask_texture);

        runningSum += sumFlow[1];

        plottingPoints[frameCounter % 1024] = runningSum;
        runningMax = Math.max(...plottingPoints);
        runningMin = Math.min(...plottingPoints);

        let scaledX = normalize(runningSum, runningMax, runningMin);

        uploadGraphPoints(gl, runningSum);
        //doDFTonPoints(gl);
        //doDFTonPoints(gl);

        //uploadGraphPoints(gl, sumFlow[1]);

        //console.log(sumFlow[0], sumFlow[1]);




      }

     render(gl, c.width, c.height, runningMax, runningMin, bmin, bmax);

     if (savingRespirationData == true) {
      //xhr.open("POST", "http://127.0.0.1:3000/test", true);
      //xhr.send([frameCounter,'flow', runningSum, '\r\n']);

      let response = await fetch('http://127.0.0.1:3000/test', {
        mode: 'no-cors',
        method: 'POST',
        body: ([frameCounter,'flow', runningSum, '\r\n'])
      });



     }







      if (firstbodyMapFound == 1)
      { 
        for (let person = 0; person < segmentation.length; person++)
        {
          if (segmentation[person].pose.score < 0.3) {
            continue;
          }
            if (bodyMapFound == 1)
            {
              skeleLines = [];
            const adjacentKeyPoints =
            posenet.getAdjacentKeyPoints(segmentation[person].pose.keypoints, 0.1);
            adjacentKeyPoints.forEach((keypoints) => {
              skeleLines.push(keypoints[0].position.x);
              skeleLines.push(keypoints[0].position.y);
              skeleLines.push(keypoints[1].position.x);
              skeleLines.push(keypoints[1].position.y);
            });

            skelePoints = [];

            for (let iter = 0; iter < segmentation[person].pose.keypoints.length; iter++)
            {
              if (segmentation[person].pose.keypoints[iter].score < 0.1) {
                continue;
              }
              skelePoints.push(segmentation[person].pose.keypoints[iter].position.x);
              skelePoints.push(segmentation[person].pose.keypoints[iter].position.y);
            }
            bodyPoseFound = 0;
          }


          gl.useProgram(renderSkeletonProgram);
          gl.bindVertexArray(gl.vaoSkeleton);
          gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
          gl.viewport(0, 240, c.width / 2.0, c.height - 240);
          gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);
          let sl = Float32Array.from(skeleLines);
          gl.bufferSubData(gl.ARRAY_BUFFER, 0, sl, 0, skeleLines.length);
          gl.lineWidth(5);
          gl.drawArrays(gl.LINES, 0, skeleLines.length / 2);     
          gl.bindVertexArray(null);

          gl.useProgram(renderSkeletonProgram);
          gl.bindVertexArray(gl.vaoSkeleton);
          gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
          gl.viewport(0, 240, c.width / 2.0, c.height - 240);
          gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);
          let sp = Float32Array.from(skelePoints);
          gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);
          gl.drawArrays(gl.POINTS, 0, skelePoints.length / 2);     
          gl.bindVertexArray(null);

          }
 
      }

      if (firstBodyPoseFound == 1)
      {
        if (bodyPoseFound == 1)
        {
          const adjacentKeyPoints =
          posenet.getAdjacentKeyPoints(bodyPose.keypoints, 0.001);
          // // adjacentKeyPoints.forEach((keypoints) => {
          // //   skelePoints.push(keypoints[0].position.x);
          // //   skelePoints.push(keypoints[0].position.y);
          // //   //skelePoints.push(keypoints[1].position[0]);
          // //   //skelePoints.push(keypoints[1].position[1]);
          // // });
          //console.log(bodyPose);
          skelePoints = [];
          for (let iter = 0; iter < bodyPose.keypoints.length; iter++)
          {
            skelePoints.push(bodyPose.keypoints[iter].position.x);
            skelePoints.push(bodyPose.keypoints[iter].position.y);
          }
          bodyPoseFound = 0;
        }
        gl.useProgram(renderSkeletonProgram);
        gl.bindVertexArray(gl.vaoSkeleton);
        gl.uniform2fv(gl.getUniformLocation(renderSkeletonProgram, "imageSize"), imageSize);
        gl.viewport(c.width / 2.0, 240, c.width / 2.0, c.height - 240);
        gl.bindBuffer(gl.ARRAY_BUFFER, gl.skeleton_buffer);
        let sp = Float32Array.from(skelePoints);
        gl.bufferSubData(gl.ARRAY_BUFFER, 0, sp, 0, skelePoints.length);
        gl.drawArrays(gl.POINTS, 0, skelePoints.length);     
        gl.bindVertexArray(null);
      }



      if ((frameAvailableColor || videoLoaded) && (gl.newImage == 1 || checkFramesFlag == false)) {
        // for (let lvl = 0; lvl < numberOflevels; lvl++) {
        //   //copyImage(gl, gl.lastColor_texture, gl.color_texture, lvl, imageSize[0], imageSize[1], gl.RGBA8UI);
        //  // copyImage(gl, gl.lastGradient_texture, gl.gradient_texture, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl, gl.RGBA16F);
        //   //copyImage(gl, gl.lastGrey_texture, gl.grey_texture, lvl, imageSize[0] >> lvl, imageSize[1] >> lvl, gl.R32F);
        // }
          let tempVal = gl.lastColor_texture;
          gl.lastColor_texture = gl.color_texture;
          gl.color_texture = tempVal;
          
          let tempVal0 = gl.lastGradient_texture;
          gl.lastGradient_texture = gl.gradient_texture;
          gl.gradient_texture = tempVal0;

          gl.newImage = 0;

      }



      frameCounter++;
      stats.end();

        //await sleep(30);


      if (!this.paused)
        window.requestAnimationFrame(_frameLoop);

    }






    // Creates WebGL/WebGL2 context used to upload depth video to texture,
    // read the pixels to Float buffer and optionElally render the texture.
    function _configureGLContext() {
      const canvas = document.getElementById("canvasGL");
      var ctx = canvas.getContext('webgl2-compute', {antialias: false});

      canvas.addEventListener('mousedown', function(e) {
        getCursorPosition(canvas, e)
      });

      if (ctx) {
        // The extension tells us if we can use single component R32F texture format.
        ctx.color_buffer_float_ext = ctx.getExtension('EXT_color_buffer_float');
        ctx.oes_texture_float_linear = ctx.getExtension('OES_texture_float_linear');

        if (!ctx.color_buffer_float_ext) {
          console.log("not supporting ext float");
        }
        if (!ctx.oes_texture_float_linear) {
          console.log("not supporting oes float");
        }
      } 
      else {
        document.getElementById("no-support").style.display = 'block';
        return;
        ctx = canvas.getContext("webgl");
        ctx.getExtension("OES_texture_float");
      }

      return ctx;
    }

    function initGL(gl) {

      // VERTEX FRAGMENT SHADERS

      var numTextureUnits = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
      for (var unit = 0; unit < numTextureUnits; ++unit) {
        gl.activeTexture(gl.TEXTURE0 + unit);
        gl.bindTexture(gl.TEXTURE_2D, null);
      }

      copyImageProgram = createComputeProgram(gl, copyImageSource);


      renderProgram = createRenderProgram(gl, vertexShaderSource, fragmentShaderSource);
      renderPlottingProgram = createRenderProgram(gl, plottingVertexShaderSource, plottingFragmentShaderSource);
      renderSkeletonProgram = createRenderProgram(gl, skeletonVertexShaderSource, skeletonFragmentShaderSource);

      copyImageProgram = createComputeProgram(gl, copyImageSource);
      genMipMapProgram = createComputeProgram(gl, genMipMapSource);
      checkIfNewImageProgram = createComputeProgram(gl, checkIfNewImageSource);
      
      plottingBufferProgram = createComputeProgram(gl, plottingBufferSource);  

      dft1DProgram = createComputeProgram(gl, dft1DSource);
      dft2DProgram = createComputeProgram(gl, dft2DSource);
      fft1DProgram = createComputeProgram(gl, fft1DSource);
      fft2DProgram = createComputeProgram(gl, fft2DSource);

      edgeDetectProgram = createComputeProgram(gl, edgeDetectSource);
      disSearchProgram = createComputeProgram(gl, disSearchSource);
      disDensificationProgram = createRenderProgram(gl, disDensificationVertexShaderSource, disDensificationFragmentShaderSource);
      getFlowFromPartProgram = createComputeProgram(gl, getFlowFromPartSource);
      getFlowFromPointProgram = createComputeProgram(gl, getFlowFromPointSource);
      makeMaskFromPointsProgram = createComputeProgram(gl, makeMaskFromPointsSource);

    }

    function setBuffers(gl) {

         
      gl.enable(gl.BLEND);
      gl.blendFunc(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA);




      gl.useProgram(renderProgram);
      vaoRender = gl.createVertexArray();
      gl.bindVertexArray(vaoRender);

      var vertex_location = gl.getAttribLocation(renderProgram, "v");
      gl.enableVertexAttribArray(vertex_location);

      var vertex_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, vertex_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0,0,1,0,1,1,0,1]), gl.STATIC_DRAW);

      var index_buffer= gl.createBuffer();
      gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, index_buffer);
      gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, new Uint16Array([0,1,2,0,2,3]), gl.STATIC_DRAW);

      gl.bindBuffer(gl.ARRAY_BUFFER, gl.vertex_buffer);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);


      gl.useProgram(renderSkeletonProgram);
      vaoSkeleton = gl.createVertexArray();
      gl.bindVertexArray(vaoSkeleton);

      let arrSkele = new Float32Array(100);
      var skeleton_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, skeleton_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, arrSkele, gl.DYNAMIC_COPY);

      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);

      let checkData = new Uint32Array(1);
      var ssboCheckData = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboCheckData);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, checkData, gl.DYNAMIC_COPY);

      let chestFlowData = new Float32Array(16 * 2);
      var ssboChestFlowData = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboChestFlowData);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, chestFlowData, gl.DYNAMIC_COPY);

      gl.useProgram(disDensificationProgram);
      vaoDensify = gl.createVertexArray();
      gl.bindVertexArray(vaoDensify);

      let arrDensify = new Int32Array(4 * 2);


      var sparsePix_buffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, sparsePix_buffer);
      gl.bufferData(gl.ARRAY_BUFFER, arrDensify, gl.STATIC_DRAW);

      gl.bindBuffer(gl.ARRAY_BUFFER, gl.sparsePix_buffer);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);


      gl.bindVertexArray(null);



      gl.useProgram(renderPlottingProgram);
      vaoPlotting = gl.createVertexArray();
      gl.bindVertexArray(vaoPlotting);

      let emptyGraphPoints = new Float32Array(2*1024);
      var ssboGraphX = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboGraphX);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);

      var ssboDFT1D0 = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboDFT1D0);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);

      var ssboDFT1D1 = gl.createBuffer();
      gl.bindBuffer(gl.SHADER_STORAGE_BUFFER, ssboDFT1D1);
      gl.bufferData(gl.SHADER_STORAGE_BUFFER, emptyGraphPoints, gl.DYNAMIC_COPY);



      gl.bindBuffer(gl.ARRAY_BUFFER, ssboGraphX);
      gl.enableVertexAttribArray(0);
      gl.vertexAttribPointer(0, 2, gl.FLOAT, false, 0, 0);

      gl.bindBuffer(gl.ARRAY_BUFFER, ssboDFT1D1);
      gl.enableVertexAttribArray(1);
      gl.vertexAttribPointer(1, 2, gl.FLOAT, false, 0, 0);

      gl.bindVertexArray(null);




      gl.vertex_buffer = vertex_buffer;
      gl.vertex_location = vertex_location;
      gl.index_buffer = index_buffer;

      gl.sparsePix_buffer = sparsePix_buffer;



      gl.vaoRender = vaoRender;
      gl.vaoSkeleton = vaoSkeleton;
      gl.vaoPlotting = vaoPlotting;
      gl.vaoDensify = vaoDensify;

      gl.skeleton_buffer = skeleton_buffer;

gl.ssboCheckData = ssboCheckData;
gl.ssboChestFlowData = ssboChestFlowData;
gl.ssboGraphX = ssboGraphX;
gl.ssboDFT1D0 = ssboDFT1D0;
gl.ssboDFT1D1 = ssboDFT1D1;

gl.rndrLevel = rndrLevel;

gl.renderColor = renderColor;
gl.renderGrad = renderGrad;
gl.renderFlow = renderFlow;


    } 
    
    function setTextures(gl) {


      var mask_texture = generateTexture(gl, gl.TEXTURE_2D, gl.R32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST_MIPMAP_NEAREST);

      var color_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);
      var lastColor_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var gradient_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);
      var lastGradient_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var densify_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var flow_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0], imageSize[1], 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var sparseFlow_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, numberOflevels, imageSize[0] / 4.0, imageSize[1] / 4.0, 1, gl.LINEAR, gl.LINEAR_MIPMAP_NEAREST);

      var render_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA8UI, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var test_texture = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);

      var srcTex = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);
      var dstTex = generateTexture(gl, gl.TEXTURE_2D, gl.RGBA32F, 1, imageSize[0], imageSize[1], 1, gl.NEAREST, gl.NEAREST);



      //Texture

      var frameBuffers = [];

      for (let lvl = 0; lvl < numberOflevels; lvl++) {
        var fb = gl.createFramebuffer();
        gl.bindFramebuffer(gl.FRAMEBUFFER, fb);

        let depthTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, depthTexture);

        gl.texImage2D(gl.TEXTURE_2D, 0, gl.DEPTH_COMPONENT24,
                        imageSize[0] >> lvl, imageSize[1] >> lvl, 0,
                        gl.DEPTH_COMPONENT, gl.UNSIGNED_INT, null);

        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
        gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.TEXTURE_2D, depthTexture, 0);
        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, densify_texture, lvl);
        //gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT1, gl.TEXTURE_2D, topFlow_texture, lvl);

        const status = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
        console.log(`can ${status === gl.FRAMEBUFFER_COMPLETE ? "" : "NOT "}render to R32`);

        gl.bindFramebuffer(gl.FRAMEBUFFER, null);

        frameBuffers.push(fb);

      }

      gl.frameBuffers = frameBuffers;



      gl.newImage = newImage;

      if (gl.color_texture != null) {
        delTexture(gl, gl.color_texture);
      }
      gl.color_texture = color_texture;
      if (gl.lastColor_texture != null) {
        delTexture(gl, gl.lastColor_texture);
      }
      gl.lastColor_texture = lastColor_texture;
      if (gl.gradient_texture != null) {
        delTexture(gl, gl.gradient_texture);
      }
      gl.gradient_texture = gradient_texture;
      if (gl.lastGradient_texture != null) {
        delTexture(gl, gl.lastGradient_texture);
      }
      gl.lastGradient_texture = lastGradient_texture;
      if (gl.densify_texture != null) {
        delTexture(gl, gl.densify_texture);
      }
      gl.densify_texture = densify_texture;
      if (gl.flow_texture != null) {
        delTexture(gl, gl.flow_texture);
      }
      gl.flow_texture = flow_texture;
      if (gl.sparseFlow_texture != null) {
        delTexture(gl, gl.sparseFlow_texture);
      }
      gl.sparseFlow_texture = sparseFlow_texture;
      if (gl.render_texture != null) {
        delTexture(gl, gl.render_texture);
      }
      gl.render_texture = render_texture;
      if (gl.test_texture != null) {
        delTexture(gl, gl.test_texture);
      }
      gl.test_texture = test_texture;
      if (gl.mask_texture != null) {
        delTexture(gl, gl.mask_texture);
      }
      gl.mask_texture = mask_texture;

      if (gl.srcTex != null) {
        delTexture(gl, gl.srcTex);
      }
      gl.srcTex = srcTex;
      if (gl.dstTex != null) {
        delTexture(gl, gl.dstTex);
      }
      gl.dstTex = dstTex;
    }

    async function loadStream(deviceId) {
      stopVideo(videos.color);
    

      const getUserMediaColor = () => {
        // add ?allow=all to URL to allow listing all devices (incl. those not supporting depth).
        //if (!deviceId && (new URL(window.location)).searchParams.get("allow") !== "all") {
          return getColorStream(imageSize[0], imageSize[1]);
        //}

        const constraints = {
          video: {
            deviceId: deviceId ? { exact: deviceId } : {}
          }
        }

        return navigator.mediaDevices.getUserMediaColor(constraints);
      }

      try {
        const streamColor = await getUserMediaColor();
        this.videoColor.srcObject = streamColor;
        this.videoColor.width = imageSize[0];
        this.videoColor.height = imageSize[1];
        videos.color = this.videoColor;
        

        //videos.color = this.videoDepth;

        const tracksColor = streamColor.getVideoTracks()[0];
        if (tracksColor.getSettings) {
          this.colorDeviceId = tracksColor.getSettings().deviceId;
        }

      } catch (err) {
        console.error(err);
      }
    }
  //});





  function populateSelectElement(devices) {
    const selectEl = document.querySelector('#selectVideoDevice');
    //const videoStreamEl = document.querySelector('video-stream');

    let selected = selectEl.value;

    while (selectEl.firstChild) {
      selectEl.removeChild(selectEl.firstChild);
    }

    let selectedDeviceStillExists = false;
    for (let i = 0; i < devices.length; ++i) {
      const info = devices[i];
      if (info.kind !== 'videoinput') {
        continue;
      }

      const optionEl = document.createElement('option');
      optionEl.value = info.deviceId;
      optionEl.text = info.label || 'camera ' + (selectEl.length + 1);
      selectEl.appendChild(optionEl);

      if (optionEl.value === selected) {
        selectedDeviceStillExists = true;
      }
    }

    if (selectedDeviceStillExists) {
      selectEl.value = selected;
    } else if (!selected) {
      // If no other device is selected, set the initial selection to depth device.
      //if (videoStreamEl.colorDeviceId) {
      //  selectEl.value = videoStreamEl.colorDeviceId;
      //}
    }


  }



  function onLoad() {
    gl = this._configureGLContext();
    initGL(gl);
    setTextures(gl);
    setBuffers(gl);
  }



  function loadWebcam() {





    //const videoStreamEl = document.querySelector('video-stream');
    const selectEl = document.querySelector('#selectVideoDevice');

    selectEl.onchange = async event => {
      selectEl.disabled = true;
      const deviceId = event.target.value;

      await loadStream(deviceId);

      const devices = await navigator.mediaDevices.enumerateDevices();
      populateSelectElement(devices);
      // if (selectedtab.value != "basic") {
      //   // It is on by default; stop rendering it if not visible.
      //   stopBasicTab();
      // }

      selectEl.disabled = false;
    };
    selectEl.dispatchEvent(new Event('change', { 'bubbles': true }))
  }
</script>
</html>
